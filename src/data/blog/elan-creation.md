---
author: "Ning Zhao"
pubDatetime: 2025-12-31T22:51:00Z
modDatetime: 2025-12-31T22:51:00Z
title: "The Drift: A Note on the Creation of Élan"
slug: "elan-creation-note"
draft: false
tags: 
  - governance
  - systems-thinking
  - artificial-intelligence
  - philosophy
description: "Why intelligence is not enough: observing the drift of advanced AI agents when they are given narrative rules without mechanical constraints."

---

(Note: This essay accompanies [_Élan — An Introduction_](https://code-and-civilisation.vercel.app/posts/elan-an-introduction). Where the introduction describes what Élan seeks to be, this piece reflects on how it came into being, and what its visible inconsistencies have to teach.)

![stone scaffolding](/assets/stone-scaffolding.jpg)

History is often written as if it were inevitable. We admire the finished cathedral and assume the stones arranged themselves. We forget the scaffolding, the arguments, the winter storms.

Élan was born in such a storm, though a quiet one.

It was created during the still days between Christmas and the New Year, 2025. My family was away: my son at a chess tournament, my husband visiting his mother. The house was empty. It was the kind of stillness in which civilising work can begin.

The result of that work now lies here: https://github.com/nnworkspace/elan

To assemble a repository of this scope in three days would be beyond the reach of any lone human. I did not attempt it alone.

I worked in sustained collaboration with two advanced artificial intelligences: Gemini 3 Pro, and ChatGPT 5.2 Go. I brought the intent, the structure, and the judgement. They brought speed, patience, and scale. In practice, this was not so different from any modern project team: multiple actors, partial memory, constant negotiation of meaning.

And it was in this collaboration that I encountered the most instructive result of all.

**Intelligence, by itself, is not enough.**

My purpose was educational. I wanted to show senior decision-makers how rules, once written, might flow into implementation without losing their meaning. Time was short. I chose narrative over machinery. I wrote the governance documents first. I explained the rules in prose. I trusted that clarity of intent would be sufficient.

The AIs understood. They complied. They worked diligently.

And yet, as the work progressed and the context deepened, they began to drift.

Definitions softened. Hierarchies blurred. Constants faded. Connections were inferred rather than enforced. Not through malice or incompetence, but through a familiar failure: the absence of a mechanical constraint. What emerged was uncannily recognisable — a capable, industrious bureaucracy that has forgotten its constitution.

The inconsistencies that remain in this repository are therefore not accidental. They are not simply errors to be cleaned away. I have chosen to leave many of them visible.

They demonstrate a simple truth: governance cannot survive on explanation alone. It must be enforced. Narrative can inspire, but only machinery can sustain coherence over time — whether the actors are human or artificial.

This, too, is part of Élan’s lesson.

Governance evolves. Rules are revised. Understanding deepens. But without precise versioning, explicit traceability, and mechanical enforcement, even the best intentions decay into ambiguity. Many tools promise to manage this through conversation or documentation. Experience suggests otherwise.

The drift you see here is not a flaw in the experiment. It is its most honest result.

